{
    "version": "0.9.2",
    "description": "Get up and running with large language models locally.",
    "homepage": "https://ollama.com/",
    "license": "MIT",
    "url": "https://github.com/likelovewant/ollama-for-amd/releases/download/v0.9.2/OllamaSetup.exe",
    "hash": "cc4b991dcb282dab031a25c3c6cf90d427861ee4d615ce708f12ec53cb9e6e8c",
    "persist_link": [
        [
            "$env:UserProfile\\.ollama",
            "UserProfile"
        ],
        [
            "$env:LocalAppData\\Ollama",
            "LocalAppData"
        ]
    ],
    "pre_install": [
        "if ($architecture -eq '64bit') {",
        "   Get-ChildItem \"$dir\\*,1.*\" -Recurse | Rename-Item -NewName { $_.FullName -replace ',1\\.', '.' }",
        "   Get-ChildItem \"$dir\\*,2.*\" -Recurse | Remove-Item",
        "} else {",
        "   Get-ChildItem \"$dir\\*,2.*\" -Recurse | Rename-Item -NewName { $_.FullName -replace ',2\\.', '.' }",
        "   Get-ChildItem \"$dir\\*,1.*\" -Recurse | Remove-Item",
        "}"
    ],
    "innosetup": true,
    "installer": {
        "script": "& \"$bucketsdir\\$bucket\\scripts\\ollama-amd\\install.ps1\""
    },
    "pre_uninstall": "Stop-Process -Name 'ollama*'",
    "bin": "ollama.exe",
    "shortcuts": [
        [
            "ollama app.exe",
            "Ollama",
            "",
            "app.ico"
        ]
    ],
    "checkver": {
        "github": "https://github.com/likelovewant/ollama-for-amd"
    },
    "autoupdate": {
        "url": "https://github.com/likelovewant/ollama-for-amd/releases/download/v$version/OllamaSetup.exe",
        "hash": {
            "url": "$baseurl/sha256sum.txt"
        }
    }
}
