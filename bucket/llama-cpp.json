{
    "version": "b3452",
    "description": "LLaMA C++ implementation for Windows with CUDA support",
    "homepage": "https://github.com/ggerganov/llama.cpp",
    "license": "MIT",
    "architecture": {
        "64bit": {
            "url": "https://github.com/ggerganov/llama.cpp/releases/download/b3452/llama-b3452-bin-win-cuda-cu12.2.0-x64.zip"
        }
    },
    "bin": [
        ["llama-baby-llama.exe", "llama-baby-llama"],
        ["llama-batched-bench.exe", "llama-batched-bench"],
        ["llama-batched.exe", "llama-batched"],
        ["llama-bench-matmult.exe", "llama-bench-matmult"],
        ["llama-bench.exe", "llama-bench"],
        ["llama-cli.exe", "llama-cli"],
        ["llama-convert-llama2c-to-ggml.exe", "llama-convert-llama2c-to-ggml"],
        ["llama-cvector-generator.exe", "llama-cvector-generator"],
        ["llama-embedding.exe", "llama-embedding"],
        ["llama-eval-callback.exe", "llama-eval-callback"],
        ["llama-export-lora.exe", "llama-export-lora"],
        ["llama-finetune.exe", "llama-finetune"],
        ["llama-gbnf-validator.exe", "llama-gbnf-validator"],
        ["llama-gguf-hash.exe", "llama-gguf-hash"],
        ["llama-gguf-split.exe", "llama-gguf-split"],
        ["llama-gguf.exe", "llama-gguf"],
        ["llama-gritlm.exe", "llama-gritlm"],
        ["llama-imatrix.exe", "llama-imatrix"],
        ["llama-infill.exe", "llama-infill"],
        ["llama-llava-cli.exe", "llama-llava-cli"],
        ["llama-lookahead.exe", "llama-lookahead"],
        ["llama-lookup-create.exe", "llama-lookup-create"],
        ["llama-lookup-merge.exe", "llama-lookup-merge"],
        ["llama-lookup-stats.exe", "llama-lookup-stats"],
        ["llama-lookup.exe", "llama-lookup"],
        ["llama-parallel.exe", "llama-parallel"],
        ["llama-passkey.exe", "llama-passkey"],
        ["llama-perplexity.exe", "llama-perplexity"],
        ["llama-q8dot.exe", "llama-q8dot"],
        ["llama-quantize-stats.exe", "llama-quantize-stats"],
        ["llama-quantize.exe", "llama-quantize"],
        ["llama-retrieval.exe", "llama-retrieval"],
        ["llama-save-load-state.exe", "llama-save-load-state"],
        ["llama-server.exe", "llama-server"],
        ["llama-simple.exe", "llama-simple"],
        ["llama-speculative.exe", "llama-speculative"],
        ["llama-tokenize.exe", "llama-tokenize"],
        ["llama-train-text-from-scratch.exe", "llama-train-text-from-scratch"],
        ["llama-vdot.exe", "llama-vdot"]
    ],
    "checkver": {
        "github": "https://github.com/ggerganov/llama.cpp",
        "regex": "download/([\\w\\d]+)/llama-[\\w\\d]+-bin-win-cuda"
    },
    "autoupdate": {
        "architecture": {
            "64bit": {
                "url": "https://github.com/ggerganov/llama.cpp/releases/download/$version/llama-$version-bin-win-cuda-cu12.2.0-x64.zip"
            }
        }
    }
}
